{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This notebook covers:\n",
    "- Creating new features from existing data\n",
    "- Feature encoding and transformation\n",
    "- Feature scaling and normalization\n",
    "- Feature selection techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_preprocessing import DataPreprocessor\n",
    "from feature_engineering import FeatureEngineer\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EDA data\n",
    "df = pd.read_csv('../data/processed/eda_data.csv')\n",
    "print(f\"Loaded dataset with shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor and encode categorical features\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = ['gender', 'symptoms', 'diagnosis', 'previous_treatment', 'severity', 'recommended_treatment', 'outcome']\n",
    "\n",
    "# Remove risk_profile if it exists (we'll recreate it)\n",
    "if 'risk_profile' in df.columns:\n",
    "    categorical_cols.append('risk_profile')\n",
    "\n",
    "# Encode categorical features\n",
    "df_encoded = preprocessor.encode_categorical_features(df, categorical_cols)\n",
    "\n",
    "print(\"Categorical encoding completed.\")\n",
    "print(f\"Encoded dataset shape: {df_encoded.shape}\")\n",
    "\n",
    "# Show encoding mappings\n",
    "print(\"\\nEncoding mappings:\")\n",
    "for col, encoder in preprocessor.label_encoders.items():\n",
    "    print(f\"{col}: {dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# Apply all feature engineering steps\n",
    "df_engineered = feature_engineer.engineer_all_features(df_encoded)\n",
    "\n",
    "print(f\"Feature engineering completed.\")\n",
    "print(f\"Original features: {df_encoded.shape[1]}\")\n",
    "print(f\"Engineered features: {df_engineered.shape[1]}\")\n",
    "print(f\"New features added: {df_engineered.shape[1] - df_encoded.shape[1]}\")\n",
    "\n",
    "# Display new features\n",
    "new_features = [col for col in df_engineered.columns if col not in df_encoded.columns]\n",
    "print(f\"\\nNew features created: {new_features}\")\n",
    "\n",
    "df_engineered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze new features\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Age groups distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "if 'age_group' in df_engineered.columns:\n",
    "    df_engineered['age_group'].value_counts().plot(kind='bar')\n",
    "    plt.title('Age Group Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "# Severity score distribution\n",
    "plt.subplot(2, 3, 2)\n",
    "if 'severity_score' in df_engineered.columns:\n",
    "    plt.hist(df_engineered['severity_score'], bins=10, edgecolor='black')\n",
    "    plt.title('Severity Score Distribution')\n",
    "    plt.xlabel('Severity Score')\n",
    "\n",
    "# Treatment history flag\n",
    "plt.subplot(2, 3, 3)\n",
    "if 'has_previous_treatment' in df_engineered.columns:\n",
    "    df_engineered['has_previous_treatment'].value_counts().plot(kind='bar')\n",
    "    plt.title('Previous Treatment Flag')\n",
    "    plt.xticks(rotation=0)\n",
    "\n",
    "# Risk score distribution\n",
    "plt.subplot(2, 3, 4)\n",
    "if 'risk_score' in df_engineered.columns:\n",
    "    plt.hist(df_engineered['risk_score'], bins=15, edgecolor='black')\n",
    "    plt.title('Risk Score Distribution')\n",
    "    plt.xlabel('Risk Score')\n",
    "\n",
    "# Age-severity interaction\n",
    "plt.subplot(2, 3, 5)\n",
    "if 'age_severity_interaction' in df_engineered.columns:\n",
    "    plt.scatter(df_engineered['age'], df_engineered['age_severity_interaction'], alpha=0.6)\n",
    "    plt.title('Age vs Age-Severity Interaction')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Age-Severity Interaction')\n",
    "\n",
    "# Correlation with outcome\n",
    "plt.subplot(2, 3, 6)\n",
    "numerical_features = df_engineered.select_dtypes(include=[np.number]).columns\n",
    "outcome_correlations = df_engineered[numerical_features].corr()['outcome'].abs().sort_values(ascending=False)\n",
    "outcome_correlations.drop('outcome').head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Features Correlated with Outcome')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target for scaling\n",
    "feature_columns = [col for col in df_engineered.columns if col not in ['patient_id', 'outcome']]\n",
    "X = df_engineered[feature_columns]\n",
    "y = df_engineered['outcome']\n",
    "\n",
    "print(f\"Features for scaling: {X.shape[1]}\")\n",
    "print(f\"Target variable: {y.name}\")\n",
    "\n",
    "# Split data for scaling\n",
    "X_train, X_test, y_train, y_test = preprocessor.split_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_test_scaled = preprocessor.scale_features(X_train, X_test)\n",
    "\n",
    "print(\"Feature scaling completed.\")\n",
    "\n",
    "# Compare before and after scaling\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Before scaling\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.boxplot([X_train[col] for col in X_train.columns[:5]], labels=X_train.columns[:5])\n",
    "plt.title('Before Scaling (First 5 Features)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# After scaling\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.boxplot([X_train_scaled[:, i] for i in range(5)], labels=X_train.columns[:5])\n",
    "plt.title('After Scaling (First 5 Features)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Distribution comparison for one feature\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(X_train.iloc[:, 0], bins=20, alpha=0.7, label='Original')\n",
    "plt.hist(X_train_scaled[:, 0], bins=20, alpha=0.7, label='Scaled')\n",
    "plt.title(f'Distribution Comparison: {X_train.columns[0]}')\n",
    "plt.legend()\n",
    "\n",
    "# Feature statistics\n",
    "plt.subplot(2, 2, 4)\n",
    "original_stats = X_train.describe().loc[['mean', 'std']].T\n",
    "scaled_stats = pd.DataFrame(X_train_scaled).describe().loc[['mean', 'std']].T\n",
    "scaled_stats.index = X_train.columns\n",
    "\n",
    "plt.scatter(original_stats['mean'], original_stats['std'], alpha=0.7, label='Original')\n",
    "plt.scatter(scaled_stats['mean'], scaled_stats['std'], alpha=0.7, label='Scaled')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.title('Mean vs Std: Original vs Scaled')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Method 1: Statistical feature selection (ANOVA F-test)\n",
    "selector_f = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_selected_f = selector_f.fit_transform(X_train_scaled, y_train)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features_f = X_train.columns[selector_f.get_support()]\n",
    "f_scores = selector_f.scores_[selector_f.get_support()]\n",
    "\n",
    "print(\"Top 10 features by ANOVA F-test:\")\n",
    "for feature, score in zip(selected_features_f, f_scores):\n",
    "    print(f\"{feature}: {score:.2f}\")\n",
    "\n",
    "# Method 2: Mutual Information\n",
    "selector_mi = SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "X_train_selected_mi = selector_mi.fit_transform(X_train_scaled, y_train)\n",
    "\n",
    "selected_features_mi = X_train.columns[selector_mi.get_support()]\n",
    "mi_scores = selector_mi.scores_[selector_mi.get_support()]\n",
    "\n",
    "print(\"\\nTop 10 features by Mutual Information:\")\n",
    "for feature, score in zip(selected_features_mi, mi_scores):\n",
    "    print(f\"{feature}: {score:.4f}\")\n",
    "\n",
    "# Method 3: Random Forest Feature Importance\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features by Random Forest Importance:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature selection results\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# ANOVA F-test scores\n",
    "plt.subplot(2, 3, 1)\n",
    "f_scores_df = pd.DataFrame({\n",
    "    'feature': selected_features_f,\n",
    "    'score': f_scores\n",
    "}).sort_values('score', ascending=True)\n",
    "\n",
    "plt.barh(range(len(f_scores_df)), f_scores_df['score'])\n",
    "plt.yticks(range(len(f_scores_df)), f_scores_df['feature'])\n",
    "plt.title('ANOVA F-test Scores')\n",
    "plt.xlabel('F-score')\n",
    "\n",
    "# Mutual Information scores\n",
    "plt.subplot(2, 3, 2)\n",
    "mi_scores_df = pd.DataFrame({\n",
    "    'feature': selected_features_mi,\n",
    "    'score': mi_scores\n",
    "}).sort_values('score', ascending=True)\n",
    "\n",
    "plt.barh(range(len(mi_scores_df)), mi_scores_df['score'])\n",
    "plt.yticks(range(len(mi_scores_df)), mi_scores_df['feature'])\n",
    "plt.title('Mutual Information Scores')\n",
    "plt.xlabel('MI Score')\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "plt.subplot(2, 3, 3)\n",
    "top_rf_features = feature_importance.head(10).sort_values('importance', ascending=True)\n",
    "plt.barh(range(len(top_rf_features)), top_rf_features['importance'])\n",
    "plt.yticks(range(len(top_rf_features)), top_rf_features['feature'])\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "\n",
    "# Feature selection overlap\n",
    "plt.subplot(2, 3, 4)\n",
    "from matplotlib_venn import venn3\n",
    "set_f = set(selected_features_f)\n",
    "set_mi = set(selected_features_mi)\n",
    "set_rf = set(feature_importance.head(10)['feature'])\n",
    "\n",
    "venn3([set_f, set_mi, set_rf], ('ANOVA F-test', 'Mutual Info', 'Random Forest'))\n",
    "plt.title('Feature Selection Method Overlap')\n",
    "\n",
    "# Correlation between different scoring methods\n",
    "plt.subplot(2, 3, 5)\n",
    "# Create a comprehensive feature score dataframe\n",
    "all_scores = pd.DataFrame({'feature': X_train.columns})\n",
    "all_scores['f_score'] = selector_f.scores_\n",
    "all_scores['mi_score'] = selector_mi.scores_\n",
    "all_scores = all_scores.merge(feature_importance, on='feature')\n",
    "\n",
    "plt.scatter(all_scores['f_score'], all_scores['mi_score'], alpha=0.6)\n",
    "plt.xlabel('ANOVA F-score')\n",
    "plt.ylabel('Mutual Information Score')\n",
    "plt.title('F-score vs MI Score Correlation')\n",
    "\n",
    "# Feature importance vs correlation\n",
    "plt.subplot(2, 3, 6)\n",
    "outcome_corr = df_engineered[feature_columns + ['outcome']].corr()['outcome'].abs()\n",
    "all_scores['outcome_corr'] = all_scores['feature'].map(outcome_corr)\n",
    "\n",
    "plt.scatter(all_scores['importance'], all_scores['outcome_corr'], alpha=0.6)\n",
    "plt.xlabel('Random Forest Importance')\n",
    "plt.ylabel('Absolute Correlation with Outcome')\n",
    "plt.title('RF Importance vs Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results from different feature selection methods\n",
    "# Take features that appear in at least 2 out of 3 methods\n",
    "feature_votes = {}\n",
    "\n",
    "# Count votes for each feature\n",
    "for feature in X_train.columns:\n",
    "    votes = 0\n",
    "    if feature in set_f:\n",
    "        votes += 1\n",
    "    if feature in set_mi:\n",
    "        votes += 1\n",
    "    if feature in set_rf:\n",
    "        votes += 1\n",
    "    feature_votes[feature] = votes\n",
    "\n",
    "# Select features with at least 2 votes\n",
    "selected_features_final = [feature for feature, votes in feature_votes.items() if votes >= 2]\n",
    "\n",
    "# If we don't have enough features, add top features from RF importance\n",
    "if len(selected_features_final) < 8:\n",
    "    additional_features = feature_importance.head(15)['feature'].tolist()\n",
    "    for feature in additional_features:\n",
    "        if feature not in selected_features_final:\n",
    "            selected_features_final.append(feature)\n",
    "        if len(selected_features_final) >= 12:\n",
    "            break\n",
    "\n",
    "print(f\"Final selected features ({len(selected_features_final)}):\")\n",
    "for i, feature in enumerate(selected_features_final, 1):\n",
    "    votes = feature_votes.get(feature, 0)\n",
    "    rf_importance = feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0]\n",
    "    print(f\"{i:2d}. {feature:<25} (votes: {votes}, RF importance: {rf_importance:.4f})\")\n",
    "\n",
    "# Create final feature sets\n",
    "X_train_final = X_train[selected_features_final]\n",
    "X_test_final = X_test[selected_features_final]\n",
    "\n",
    "# Scale the final feature sets\n",
    "X_train_final_scaled, X_test_final_scaled = preprocessor.scale_features(X_train_final, X_test_final)\n",
    "\n",
    "print(f\"\\nFinal training set shape: {X_train_final_scaled.shape}\")\n",
    "print(f\"Final test set shape: {X_test_final_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary of feature engineering process\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. ORIGINAL DATASET:\")\n",
    "print(f\"   - Original features: {df.shape[1]}\")\n",
    "print(f\"   - Samples: {df.shape[0]:,}\")\n",
    "\n",
    "print(f\"\\n2. CATEGORICAL ENCODING:\")\n",
    "print(f\"   - Categorical columns encoded: {len(categorical_cols)}\")\n",
    "print(f\"   - Encoding method: Label Encoding\")\n",
    "\n",
    "print(f\"\\n3. FEATURE ENGINEERING:\")\n",
    "print(f\"   - Features after engineering: {df_engineered.shape[1]}\")\n",
    "print(f\"   - New features created: {len(new_features)}\")\n",
    "print(f\"   - New features: {', '.join(new_features)}\")\n",
    "\n",
    "print(f\"\\n4. FEATURE SCALING:\")\n",
    "print(f\"   - Scaling method: MinMaxScaler\")\n",
    "print(f\"   - Features scaled: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\n5. FEATURE SELECTION:\")\n",
    "print(f\"   - Selection methods used: 3 (ANOVA F-test, Mutual Information, Random Forest)\")\n",
    "print(f\"   - Features before selection: {X_train.shape[1]}\")\n",
    "print(f\"   - Features after selection: {len(selected_features_final)}\")\n",
    "print(f\"   - Reduction: {(1 - len(selected_features_final)/X_train.shape[1])*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n6. FINAL DATASET:\")\n",
    "print(f\"   - Training samples: {X_train_final_scaled.shape[0]:,}\")\n",
    "print(f\"   - Test samples: {X_test_final_scaled.shape[0]:,}\")\n",
    "print(f\"   - Final features: {X_train_final_scaled.shape[1]}\")\n",
    "\n",
    "print(f\"\\n7. NEXT STEPS:\")\n",
    "print(f\"   - Proceed to model training with engineered features\")\n",
    "print(f\"   - Use selected features for better model performance\")\n",
    "print(f\"   - Consider feature interactions in model selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered data and selected features\n",
    "df_engineered.to_csv('../data/processed/engineered_data.csv', index=False)\n",
    "\n",
    "# Save selected features list\n",
    "pd.DataFrame({'selected_features': selected_features_final}).to_csv('../data/processed/selected_features.csv', index=False)\n",
    "\n",
    "# Save train/test splits\n",
    "pd.DataFrame(X_train_final_scaled, columns=selected_features_final).to_csv('../data/processed/X_train_final.csv', index=False)\n",
    "pd.DataFrame(X_test_final_scaled, columns=selected_features_final).to_csv('../data/processed/X_test_final.csv', index=False)\n",
    "pd.DataFrame({'y_train': y_train}).to_csv('../data/processed/y_train.csv', index=False)\n",
    "pd.DataFrame({'y_test': y_test}).to_csv('../data/processed/y_test.csv', index=False)\n",
    "\n",
    "print(\"\\nAll engineered data and splits saved to '../data/processed/'\")\n",
    "print(\"Ready for model training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}